import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder

def run_rf_model(df, target_col='in_cadency', label_encode=True, features=None):
    df = df.copy()
    df[target_col] = df[target_col].fillna(0)
    df = df.dropna(subset=[target_col])

    if features:
        X = df[features].copy()
    else:
        X = df.drop(columns=[target_col])
    y = df[target_col]

    X.replace([np.inf, -np.inf], np.nan, inplace=True)
    for col in X.columns:
        if X[col].dtype == 'object':
            X[col] = X[col].fillna("NA")
        else:
            X[col] = X[col].fillna(0)
    for col in X.select_dtypes(include=np.number).columns:
        X[col] = np.clip(X[col], -1e10, 1e10)
    for col in X.select_dtypes(include='object').columns:
        if label_encode:
            X[col] = LabelEncoder().fit_transform(X[col].astype(str))
        else:
            X = X.drop(columns=[col])

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    clf = RandomForestClassifier(random_state=42)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    cm = confusion_matrix(y_test, y_pred)
    if cm.shape == (2, 2):
        tn, fp, fn, tp = cm.ravel()
    else:
        tn = fp = fn = tp = 0
        if len(np.unique(y_test)) == 1:
            if y_test.iloc[0] == 1:
                tp = sum(y_pred == 1)
                fn = sum(y_pred == 0)
            else:
                tn = sum(y_pred == 0)
                fp = sum(y_pred == 1)

    return {
        "Accuracy": accuracy_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred, zero_division=0),
        "Recall": recall_score(y_test, y_pred, zero_division=0),
        "F1 Score": f1_score(y_test, y_pred, zero_division=0),
        "False Positives": fp,
        "True Positives": tp,
        "True Negatives": tn,
        "False Negatives": fn,
        "Feature Importances": pd.Series(clf.feature_importances_, index=X.columns).sort_values(ascending=False)
    }

# 1️⃣ Load and preprocess your monthly data
df = pd.read_csv('file1.csv')              # Data for the month
gl_df = pd.read_csv('file2.csv')           # Additional lookup data

# 2️⃣ Downsample majority class in df
df['in_cadency'] = df['in_cadency'].fillna(0)
df_pos = df[df['in_cadency'] == 1]
df_neg = df[df['in_cadency'] == 0]
df_neg_ds = df_neg.sample(frac=1/1000, random_state=42)
df_balanced = pd.concat([df_pos, df_neg_ds]).sample(frac=1, random_state=42)

print("Original df class counts:", df['in_cadency'].value_counts().to_dict())
print("Downsampled df class counts:", df_balanced['in_cadency'].value_counts().to_dict())

# 3️⃣ Merge rate-limited df with gl_df
merged = pd.merge(df, gl_df, on='Con', how='left')
merged['in_cadency'] = merged['in_cadency'].fillna(0)
m_pos = merged[merged['in_cadency'] == 1]
m_neg_ds = merged[merged['in_cadency'] == 0].sample(frac=1/1000, random_state=42)
merged_balanced = pd.concat([m_pos, m_neg_ds]).sample(frac=1, random_state=42)

print("Original merged class counts:", merged['in_cadency'].value_counts().to_dict())
print("Downsampled merged class counts:", merged_balanced['in_cadency'].value_counts().to_dict())

# 4️⃣ Train and compare models
res_df = run_rf_model(df_balanced)
res_merged = run_rf_model(merged_balanced)

print("\n=== Results on DF only (with 1k downsampling) ===")
for k, v in res_df.items():
    if k != "Feature Importances":
        print(f"{k}: {v}")

print("\n=== Results on MERGED DF (with 1k downsampling) ===")
for k, v in res_merged.items():
    if k != "Feature Importances":
        print(f"{k}: {v}")

print("\nTop 10 Features (DF) vs (MERGED):")
print("DF:", res_df["Feature Importances"].head(10))
print("MERGED:", res_merged["Feature Importances"].head(10))
