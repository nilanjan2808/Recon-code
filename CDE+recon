# app.py
import base64
import io
import pandas as pd
from dash import Dash, dcc, html, Input, Output, State, callback_context, dash_table
import dash_bootstrap_components as dbc
from sklearn.feature_selection import mutual_info_classif

app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
server = app.server

# ---------- Utility Functions ----------
def parse_contents(contents):
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)
    try:
        return pd.read_csv(io.BytesIO(decoded))
    except Exception:
        return pd.DataFrame()

def get_anomaly_summary(df1, df2, threshold_pct):
    group_cols = ['grca_dimension2', 'grca_dimension3']

    df1['book_value'] = pd.to_numeric(df1['book_value'], errors='coerce').fillna(0.0)
    df2['book_value'] = pd.to_numeric(df2['book_value'], errors='coerce').fillna(0.0)

    df1_grouped = df1.groupby(group_cols)['book_value'].sum().reset_index().rename(columns={'book_value': 'source_value'})
    df2_grouped = df2.groupby(group_cols)['book_value'].sum().reset_index().rename(columns={'book_value': 'reference_value'})

    merged = pd.merge(df1_grouped, df2_grouped, on=group_cols, how='outer').fillna(0)
    merged['difference'] = merged['source_value'] - merged['reference_value']
    merged['pct_change'] = (merged['difference'] / (merged['reference_value'] + 1e-9)) * 100
    merged['pct_change'] = merged['pct_change'].map(lambda x: f"{x:.2f}%")
    anomalies = merged[merged['pct_change'].str.rstrip('%').astype(float).abs() > threshold_pct]
    return anomalies

def get_drilldown_data(df1, df2, dim2, dim3, selected_cdes):
    df1_filtered = df1[(df1['grca_dimension2'] == dim2) & (df1['grca_dimension3'] == dim3)]
    df2_filtered = df2[(df2['grca_dimension2'] == dim2) & (df2['grca_dimension3'] == dim3)]

    df1_grouped = df1_filtered.groupby(selected_cdes)['book_value'].sum().reset_index().rename(columns={'book_value': 'source_value'})
    df2_grouped = df2_filtered.groupby(selected_cdes)['book_value'].sum().reset_index().rename(columns={'book_value': 'reference_value'})

    merged = pd.merge(df1_grouped, df2_grouped, on=selected_cdes, how='outer').fillna(0)
    merged['difference'] = merged['source_value'] - merged['reference_value']
    merged['pct_change'] = (merged['difference'] / (merged['reference_value'] + 1e-9)) * 100
    merged['pct_change'] = merged['pct_change'].map(lambda x: f"{x:.2f}%")

    return merged

def get_suggested_cdes(df1, df2):
    common_cols = set(df1.columns).intersection(set(df2.columns))
    exclude_exact = ['book_value', 'grca_dimension2', 'grca_dimension3']
    exclude_keywords = ['id', 'key', 'code', 'value', 'amount', 'date', 'time']

    suggested = []
    for col in common_cols:
        if col in exclude_exact or any(kw in col.lower() for kw in exclude_keywords):
            continue
        if df1[col].nunique(dropna=True) in [0, 1] or df2[col].nunique(dropna=True) in [0, 1]:
            continue
        if pd.api.types.is_numeric_dtype(df1[col]):
            continue
        if df1[col].dtype in ['object', 'category', 'bool'] or df1[col].nunique() < 50:
            suggested.append(col)

    return suggested

def get_density_ranked_cdes(df1, df2):
    summary = get_anomaly_summary(df1, df2, 0)
    summary['anomaly_flag'] = summary['pct_change'].str.rstrip('%').astype(float).abs() > 10

    df = df1.merge(df2, on=['grca_dimension2', 'grca_dimension3'], suffixes=('_src', '_ref'))
    df = df.merge(summary[['grca_dimension2', 'grca_dimension3', 'anomaly_flag']], on=['grca_dimension2', 'grca_dimension3'], how='left').fillna(False)

    candidates = get_suggested_cdes(df1, df2)
    enc_df = pd.get_dummies(df[candidates], dummy_na=True).astype(int)
    if not enc_df.empty:
        scores = mutual_info_classif(enc_df, df['anomaly_flag'], discrete_features=True)
        ranking = pd.DataFrame({'CDE': enc_df.columns, 'score': scores}).sort_values(by='score', ascending=False)
        return ranking
    return pd.DataFrame(columns=['CDE', 'score'])

# ---------- Layout ----------
anomaly_tab = dbc.Container([
    html.H2("\U0001F50D Anomaly Detection & Reconciliation Tool", className="text-center my-4"),

    dbc.Row([
        dbc.Col([
            html.Label("Upload Source File:"),
            dcc.Upload(id='upload-source', children=dbc.Button('Upload Source', color='primary', className='w-100'), className='mb-2'),
        ], width=4),

        dbc.Col([
            html.Label("Upload Reference File:"),
            dcc.Upload(id='upload-reference', children=dbc.Button('Upload Reference', color='secondary', className='w-100'), className='mb-2'),
        ], width=4),

        dbc.Col([
            html.Label("Select Threshold (%):"),
            dcc.Dropdown(id='threshold-dropdown', options=[{'label': f'{i}%', 'value': i} for i in range(0, 105, 5)], value=10, className='mb-2')
        ], width=4),
    ], className='mb-4'),

    html.H4("\U0001F6A8 Anomaly Summary Table", className='text-info'),
    dash_table.DataTable(id='anomaly-table', row_selectable='single', page_size=10, style_table={'overflowX': 'auto'},
        style_cell={'minWidth': '120px', 'whiteSpace': 'normal', 'textAlign': 'center'}),

    html.Hr(),
    html.Div(id='drilldown-section', children=[
        html.H4("\U0001F9D0 Drilldown Details", className='text-secondary'),
        dcc.Dropdown(id='cde-selector', multi=True, placeholder='Select CDEs for drilldown...'),
        dash_table.DataTable(id='drilldown-table', page_size=10, style_table={'overflowX': 'auto', 'maxHeight': '600px', 'overflowY': 'scroll'},
            style_cell={'minWidth': '120px', 'whiteSpace': 'normal', 'textAlign': 'center'})
    ]),

    html.Div("Developed by Finance Ninjas", className="text-center text-muted mt-4")
])

anomaly_density_tab = dbc.Container([
    html.H3("\U0001F9EA Anomaly Density-Based Filtering", className="text-center my-4"),
    html.P("CDEs ranked by their ability to explain anomalies.", className="text-center"),
    dash_table.DataTable(id='density-ranking-table', page_size=10, style_table={'overflowX': 'auto'},
                         style_cell={'minWidth': '100px', 'textAlign': 'center'})
])

app.layout = dbc.Container([
    dcc.Tabs(id='main-tabs', value='anomaly', children=[
        dcc.Tab(label='Anomaly Dashboard', value='anomaly'),
        dcc.Tab(label='Anomaly Density-Based Filtering', value='anomaly_density')
    ]),
    html.Div(id='tabs-content')
], fluid=True)

# ---------- Callbacks ----------
@app.callback(
    Output('tabs-content', 'children'),
    Input('main-tabs', 'value')
)
def render_tab(tab):
    if tab == 'anomaly_density':
        return anomaly_density_tab
    return anomaly_tab

@app.callback(
    Output('anomaly-table', 'data'),
    Output('anomaly-table', 'columns'),
    Output('cde-selector', 'options'),
    Input('upload-source', 'contents'),
    Input('upload-reference', 'contents'),
    State('threshold-dropdown', 'value'),
    prevent_initial_call=True
)
def update_anomaly_table(src_contents, ref_contents, threshold):
    if not src_contents or not ref_contents:
        return [], [], []
    df1 = parse_contents(src_contents)
    df2 = parse_contents(ref_contents)
    anomalies = get_anomaly_summary(df1, df2, threshold)
    columns = [{'name': col, 'id': col} for col in anomalies.columns]
    cde_options = [{'label': col, 'value': col} for col in get_suggested_cdes(df1, df2)]
    app.server.df1 = df1
    app.server.df2 = df2
    return anomalies.to_dict('records'), columns, cde_options

@app.callback(
    Output('drilldown-table', 'data'),
    Output('drilldown-table', 'columns'),
    Input('anomaly-table', 'selected_rows'),
    State('anomaly-table', 'data'),
    State('cde-selector', 'value'),
    prevent_initial_call=True
)
def display_drilldown_table(selected_rows, table_data, selected_cdes):
    if not selected_rows or not selected_cdes:
        return [], []
    row = table_data[selected_rows[0]]
    dim2, dim3 = row['grca_dimension2'], row['grca_dimension3']
    df1, df2 = app.server.df1, app.server.df2
    drill = get_drilldown_data(df1, df2, dim2, dim3, selected_cdes)
    columns = [{'name': col, 'id': col} for col in drill.columns]
    return drill.to_dict('records'), columns

@app.callback(
    Output('density-ranking-table', 'data'),
    Output('density-ranking-table', 'columns'),
    Input('main-tabs', 'value')
)
def update_density_table(tab):
    if tab != 'anomaly_density':
        return [], []
    df1, df2 = getattr(app.server, 'df1', pd.DataFrame()), getattr(app.server, 'df2', pd.DataFrame())
    if df1.empty or df2.empty:
        return [], []
    ranking_df = get_density_ranked_cdes(df1, df2)
    return ranking_df.to_dict('records'), [{'name': c, 'id': c} for c in ranking_df.columns]

if __name__ == '__main__':
    app.run_server(debug=True)
