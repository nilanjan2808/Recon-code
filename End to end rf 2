import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import (
    classification_report, confusion_matrix,
    precision_recall_curve, average_precision_score
)

def run_rf_model(df, target_col, feature_cols=None, test_size=0.2, random_state=42, n_estimators=100, max_depth=None):
    df = df.copy()

    # Drop rows where target is missing
    df = df[~df[target_col].isnull()]

    # Detect feature columns if not given
    if feature_cols is None:
        feature_cols = [col for col in df.columns if col != target_col]

    X = df[feature_cols]
    y = df[target_col]

    # Separate numeric and categorical columns
    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
    cat_cols = [col for col in X.columns if col not in num_cols]

    # Replace inf with nan
    X.replace([np.inf, -np.inf], np.nan, inplace=True)

    # Impute numeric with 0
    if num_cols:
        X[num_cols] = SimpleImputer(strategy='constant', fill_value=0).fit_transform(X[num_cols])

    # Impute categorical with 'NA' and label encode
    if cat_cols:
        X[cat_cols] = X[cat_cols].fillna('NA')
        for col in cat_cols:
            le = LabelEncoder()
            X[col] = le.fit_transform(X[col])

    X = X[feature_cols]

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=test_size, random_state=random_state)

    # Class imbalance warning
    print("Target class distribution (train):", y_train.value_counts().to_dict())

    # Train model
    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)
    clf.fit(X_train, y_train)

    y_pred = clf.predict(X_test)
    y_proba = clf.predict_proba(X_test)[:, 1]

    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))

    # Feature Importance
    importances = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)
    print("\nTop 10 Feature Importances:")
    print(importances.head(10))

    # Rule-based suggestion
    top_features = importances.head(3).index.tolist()
    rules = {}

    for feature in top_features:
        if feature in num_cols:
            pos_vals = X_train.loc[y_train == 1, feature]
            threshold = pos_vals.quantile(0.1)
            rules[feature] = f"{feature} >= {threshold:.3f}"
        else:
            rules[feature] = f"{feature} in top categories"

    print("\nSuggested Rules for Flagging Exceptions:")
    for k, v in rules.items():
        print(f"- {v}")

    # Precision-Recall Curve
    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)
    avg_prec = average_precision_score(y_test, y_proba)

    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, label=f'AP = {avg_prec:.2f}')
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title("Precision-Recall Curve")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    return {
        'model': clf,
        'X_train': X_train,
        'y_train': y_train,
        'X_test': X_test,
        'y_test': y_test,
        'feature_importance': importances,
        'rules': rules,
        'precision': precision,
        'recall': recall,
        'thresholds': thresholds
    }
